{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen =  ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "test_datagen =  ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 241 images belonging to 5 classes.\n",
      "Found 134 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r\"E:\\Externship\\objects\\Train\",target_size = (64,64),batch_size = 15,class_mode = \"categorical\")\n",
    "x_test = test_datagen.flow_from_directory(r\"E:\\Externship\\objects\\Test\",target_size = (64,64),batch_size = 15,class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3) ,input_shape = (64,64,3),activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512,activation = \"relu\",kernel_initializer = \"random_uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 5,activation = \"softmax\",kernel_initializer = \"random_uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"sgd\",loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1667 - accuracy: 0.5250WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 1.1667 - accuracy: 0.5250 - val_loss: 0.9474 - val_accuracy: 0.7463\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 1.1730 - accuracy: 0.5398\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 1.0557 - accuracy: 0.5625\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 1.0997 - accuracy: 0.5442\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 1.2287 - accuracy: 0.5664\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 1.0997 - accuracy: 0.5973\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 1.0581 - accuracy: 0.5575\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 1.0031 - accuracy: 0.6062\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 0.9624 - accuracy: 0.6195\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 1.1411 - accuracy: 0.5664\n",
      "Epoch 11/15\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.9684 - accuracy: 0.6372\n",
      "Epoch 12/15\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 0.8977 - accuracy: 0.6549\n",
      "Epoch 13/15\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 0.8852 - accuracy: 0.6770\n",
      "Epoch 14/15\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.8528 - accuracy: 0.6637\n",
      "Epoch 15/15\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 0.8588 - accuracy: 0.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bc1e5be9e8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train ,steps_per_epoch = 16 ,epochs = 15,validation_data= x_test , validation_steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"object.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
